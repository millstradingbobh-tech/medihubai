<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Speech-Only Voice Recorder</title>
<style>
  body {
    font-family: system-ui;
    background: #121212;
    color: #e0e0e0;
    display: flex;
    flex-direction: column;
    align-items: center;
    padding: 2rem;
    min-height: 100vh;
    margin: 0;
  }

  button {
    padding: 1rem 2rem;
    font-size: 1.25rem;
    border: none;
    border-radius: 8px;
    cursor: pointer;
    background: #6200ee;
    color: white;
    box-shadow: 0 4px 8px rgba(98,0,238,.3);
  }

  button:disabled {
    background: #555;
    cursor: not-allowed;
  }

  pre {
    background: #1e1e1e;
    border-radius: 8px;
    padding: 1rem;
    margin-top: 1.5rem;
    width: 90vw;
    max-width: 600px;
    height: 300px;
    overflow-y: auto;
    white-space: pre-wrap;
  }

  header {
    font-size: 1.5rem;
    color: #bb86fc;
    margin-bottom: 1rem;
  }
</style>
</head>
<body>

<header>Speech-Only Recorder</header>
<button id="btn">Start Recording</button>
<pre id="log"></pre>

<script>
const btn = document.getElementById("btn");
const logEl = document.getElementById("log");

let ws, recorder, stream;
let audioCtx, analyser, dataArray;
let filteredStream;
let recording = false;
let sentenceChunks = [];

/* =====================
   SPEECH GATE CONSTANTS
===================== */
const CALIBRATION_MS = 1500;
const SPEECH_MARGIN_DB = 14;
const NOISE_LEARN_RATE = 0.05;
const GATE_HOLD_MS = 200;
const MIN_SPEECH_MS = 120;
const SILENCE_DURATION_MS = 1000;
const MIN_BLOB_SIZE = 33000;

/* =====================
   SPEECH GATE STATE
===================== */
let noiseFloorDb = -90;
let calibrated = false;
let calibrationStart = null;
let gateOpen = false;
let gateHoldUntil = 0;
let speechStart = null;
let silenceStart = null;

/* =====================
   Utils
===================== */
function log(msg) {
  logEl.textContent += `[${new Date().toLocaleTimeString()}] ${msg}\n`;
  logEl.scrollTop = logEl.scrollHeight;
}

btn.onclick = () => recording ? stopRecording() : startWS();

/* =====================
   WebSocket
===================== */
function startWS() {
  btn.disabled = true;

  const isLocalhost = ["localhost", "127.0.0.1"].includes(location.hostname);
  ws = new WebSocket(
    isLocalhost
      ? "ws://localhost:8080/ws"
      : "wss://medihubai-476149103615.australia-southeast1.run.app/ws"
  );

  ws.onopen = () => {
    log("WebSocket connected");
    ws.send(JSON.stringify({ type: "init" }));
    startRecording();
  };

  ws.onmessage = e => {
    try {
      const msg = JSON.parse(e.data);
      if (msg.type === "transcription") {
        log("You said: " + msg.text);
      }
    } catch {}
  };

  ws.onerror = stopRecording;
  ws.onclose = stopRecording;
}

/* =====================
   Recording Setup
===================== */
async function startRecording() {
  stream = await navigator.mediaDevices.getUserMedia({
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
    },
  });

  audioCtx = new AudioContext();
  const source = audioCtx.createMediaStreamSource(stream);

  /* ðŸŽ¯ Speech band filtering */
  const highPass = audioCtx.createBiquadFilter();
  highPass.type = "highpass";
  highPass.frequency.value = 120;

  const lowPass = audioCtx.createBiquadFilter();
  lowPass.type = "lowpass";
  lowPass.frequency.value = 4000;

  const destination = audioCtx.createMediaStreamDestination();

  source.connect(highPass);
  highPass.connect(lowPass);
  lowPass.connect(destination);

  filteredStream = destination.stream;

  /* ðŸ” Analyzer (unfiltered for detection) */
  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 2048;
  dataArray = new Float32Array(analyser.fftSize);
  source.connect(analyser);

  recording = true;
  btn.textContent = "Calibratingâ€¦";
  btn.disabled = false;

  startNewRecorder();
  detectSpeech();

  log("Recording started");
}

/* =====================
   MediaRecorder
===================== */
function startNewRecorder() {
  sentenceChunks = [];

  recorder = new MediaRecorder(filteredStream, { mimeType: "audio/webm" });

  recorder.ondataavailable = e => {
    if (e.data.size > 0) sentenceChunks.push(e.data);
  };

  recorder.onstop = () => {
    const blob = new Blob(sentenceChunks, { type: "audio/webm" });

    if (blob.size >= MIN_BLOB_SIZE && ws?.readyState === 1) {
      ws.send(blob);
      log(`Sent speech (${Math.round(blob.size / 1024)} KB)`);
    }

    if (recording) startNewRecorder();
  };

  recorder.start();
}

/* =====================
   Speech Detection
===================== */
function detectSpeech() {
  if (!recording) return;

  analyser.getFloatTimeDomainData(dataArray);

  let sum = 0;
  for (const v of dataArray) sum += v * v;
  const rms = Math.sqrt(sum / dataArray.length);
  const db = 20 * Math.log10(rms || 1e-8);
  const now = performance.now();

  /* -------- Calibration -------- */
  if (!calibrated) {
    calibrationStart ??= now;
    noiseFloorDb += (db - noiseFloorDb) * 0.2;
    btn.textContent = "Calibrating silenceâ€¦";

    if (now - calibrationStart > CALIBRATION_MS) {
      calibrated = true;
      noiseFloorDb = Math.min(noiseFloorDb, -45);
      noiseFloorDb = Math.max(noiseFloorDb, -75);
      log(`Noise floor: ${noiseFloorDb.toFixed(1)} dB`);
    }

    requestAnimationFrame(detectSpeech);
    return;
  }

  /* -------- Speech gate -------- */
  const threshold = noiseFloorDb + SPEECH_MARGIN_DB;

  if (db > threshold) {
    gateOpen = true;
    gateHoldUntil = now + GATE_HOLD_MS;
    speechStart ??= now;
  } else if (now > gateHoldUntil) {
    gateOpen = false;
    speechStart = null;
  }

  const speaking =
    gateOpen &&
    speechStart &&
    now - speechStart > MIN_SPEECH_MS;

  if (!speaking) {
    silenceStart ??= Date.now();
    btn.textContent = "Listeningâ€¦";

    if (Date.now() - silenceStart > SILENCE_DURATION_MS) {
      silenceStart = null;
      cutSentence();
    }

    // Learn noise slowly only when silent
    noiseFloorDb += (db - noiseFloorDb) * NOISE_LEARN_RATE;
  } else {
    btn.textContent = "ðŸŽ™ Speakingâ€¦";
    silenceStart = null;
  }

  requestAnimationFrame(detectSpeech);
}

/* =====================
   Cut sentence
===================== */
function cutSentence() {
  if (recorder?.state === "recording") recorder.stop();
}

/* =====================
   Stop everything
===================== */
function stopRecording() {
  recording = false;
  btn.textContent = "Start Recording";
  btn.disabled = false;

  recorder?.state === "recording" && recorder.stop();
  stream?.getTracks().forEach(t => t.stop());
  audioCtx?.close();
  ws?.readyState === 1 && ws.close();

  log("Recording stopped");
}
</script>

</body>
</html>

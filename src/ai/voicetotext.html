<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Voice Recorder & Silence Detection</title>
<style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen,
        Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;
      background: #121212;
      color: #e0e0e0;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 2rem;
      min-height: 100vh;
      margin: 0;
    }

    button {
      padding: 1rem 2rem;
      font-size: 1.25rem;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      background: #6200ee;
      color: white;
      transition: background-color 0.3s ease;
      box-shadow: 0 4px 8px rgb(98 0 238 / 0.3);
      user-select: none;
    }

    button:disabled {
      background: #555;
      cursor: not-allowed;
      box-shadow: none;
    }

    button:hover:not(:disabled) {
      background: #3700b3;
    }

    pre {
      background: #1e1e1e;
      border-radius: 8px;
      padding: 1rem;
      margin-top: 1.5rem;
      width: 90vw;
      max-width: 600px;
      height: 300px;
      overflow-y: auto;
      white-space: pre-wrap;
      box-shadow: inset 0 0 10px rgb(0 0 0 / 0.7);
      font-size: 1rem;
      line-height: 1.4;
    }

    header {
      margin-bottom: 1.5rem;
      font-size: 1.5rem;
      font-weight: 600;
      color: #bb86fc;
    }
  </style>
</head>
<body>

<header>Voice Recorder Playground</header>
<button id="btn">Start Recording</button>
<pre id="log"></pre>

<script>
const btn = document.getElementById("btn");
const logEl = document.getElementById("log");

let ws;
let recorder;
let stream;
let recording = false;

// Silence detection
let audioCtx, analyser, dataArray;
let silenceStart = null;

// Per-sentence buffering
let sentenceChunks = [];

const SILENCE_THRESHOLD_DB = -50;
const SILENCE_DURATION_MS = 1000;
const MIN_BLOB_SIZE = 33000;

function log(msg) {
  logEl.textContent += `[${new Date().toLocaleTimeString()}] ${msg}\n`;
  logEl.scrollTop = logEl.scrollHeight;
}

btn.onclick = () => recording ? stopRecording() : startWS();

/* =====================
   WebSocket
===================== */
function startWS() {
  btn.disabled = true;
    ws = new WebSocket("ws://0.0.0.0:3000/ws");
//   ws = new WebSocket("ws://localhost:3000/ws");
  ws.binaryType = "arraybuffer";

  ws.onopen = () => {
    log("WebSocket connected");
    startRecording();
  };

  ws.onmessage = (e) => {
    try {
      const msg = JSON.parse(e.data);
      if (msg.type === "transcription") {
        log("You said: " + msg.text);
      }
    } catch {}
  };

  ws.onerror = stopRecording;
  ws.onclose = stopRecording;
}

/* =====================
   Recording
===================== */
async function startRecording() {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true });

  audioCtx = new AudioContext();
  const source = audioCtx.createMediaStreamSource(stream);
  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 2048;
  dataArray = new Float32Array(analyser.fftSize);
  source.connect(analyser);

  recording = true;
  btn.textContent = "Stop Recording";
  btn.disabled = false;

  startNewRecorder();
  detectSilence();

  log("Recording started");
}

/* =====================
   MediaRecorder per sentence
===================== */
function startNewRecorder() {
  sentenceChunks = [];

  recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });

  recorder.ondataavailable = e => {
    if (e.data.size > 0) {
      sentenceChunks.push(e.data);
    }
  };

  recorder.onstop = () => {
    const blob = new Blob(sentenceChunks, { type: "audio/webm" });

    if (blob.size >= MIN_BLOB_SIZE && ws?.readyState === WebSocket.OPEN) {
      ws.send(blob);
      log(`Sent sentence (${Math.round(blob.size / 1024)} KB)`);
    }

    // Immediately start next sentence if still recording
    if (recording) {
      startNewRecorder();
    }
  };

  recorder.start();
}

/* =====================
   Silence Detection
===================== */
function detectSilence() {
  if (!recording) return;

  analyser.getFloatTimeDomainData(dataArray);

  let sum = 0;
  for (const v of dataArray) sum += v * v;
  const rms = Math.sqrt(sum / dataArray.length);
  const db = 20 * Math.log10(rms || 1e-8);

  if (db < SILENCE_THRESHOLD_DB) {
    silenceStart ??= Date.now();
    if (Date.now() - silenceStart > SILENCE_DURATION_MS) {
      silenceStart = null;
      cutSentence();
    }
  } else {
    silenceStart = null;
  }

  requestAnimationFrame(detectSilence);
}

/* =====================
   Cut sentence (FINALIZE WEBM)
===================== */
function cutSentence() {
  if (!recorder || recorder.state !== "recording") return;
  recorder.stop(); // ðŸ”‘ FINALIZES WEBM
}

/* =====================
   Stop everything
===================== */
function stopRecording() {
  recording = false;
  btn.textContent = "Start Recording";
  btn.disabled = false;

  if (recorder?.state === "recording") {
    recorder.stop();
  }

  stream?.getTracks().forEach(t => t.stop());
  audioCtx?.close();

  if (ws?.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({ type: "stop" }));
    ws.close();
  }

  log("Recording stopped");
}
</script>
</body>
</html>
